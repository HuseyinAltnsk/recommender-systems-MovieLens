# Experiment Results
__We can come up with two different sets of best parameters for our dataset based on the priorities in the given system. If accuracy is prioritized over coverage, our
experimentation results suggested the use of Euclidean similarity algorithm with no significance weighting and threshold seems to be the best option (Introducing
significance weighting and similarity threshold with Euclidean limits the coverage further.).__ The item-based version of this system would produce more accurate
but fewer recommendations than user-based, so the choice of CF algorithm depends on the need for coverage. __If coverage is prioritized over accuracy, a user-based CF
recommender with Pearson similarity algorithm, no significance weighting and no similarity threshold seems to be the best choice.__
__This result aligned with our initial hypothesis, claiming that item-based CF generates more accurate recommendations than user-based CF.__ We initially argued
that the sparsity issue would affect the user-based recommender more than the item-based one. Even though this might still be the case, we received far fewer
recommendations from the item-based recommender relative to the user-based one, which raises some concerns about the coverage of this CF algorithm. However, we only
noted the number of recommendations for a selection of our experiments. For future work, it would be interesting to do a similar study for coverage instead of
errors to see which parameters yield the most optimal result for both coverage and accuracy. Additionally, the team also predicted that similarity threshold would
not result in better recommendations, which our results agreeed with. __Also, we initially claimed that significance weighting is important to devalue similarities
that only have a few ratings in common. Our results showed that this is true for item-based CF, but it is not the case with user-based CF.__ A possible reason for
this might be that n/25, which is the smallest significance weighting parameter we used, is too high for user-based recommenders. It‚Äôs probably very rare for two
users to have more than 25 ratings in common. Therefore, there is some room for future work to explore the effect of significance weightings of n/5, n/10, and n/15
for user-based systems.

Furthermore, one of our hypotheses was that Spearman similarity algorithm will perform worse than Pearson, because movie ratings data is not naturally-rankable.
__This was confirmed by our results, which rejected the claims made by Herlocker that said Spearman is a promising similarity calculation method. [1]__

The team disregarded the results generated by Euclidean similarity for the most of the paper, because it provided much less coverage than Pearson and Spearman.
However, the few recommendations generated by Euclidean were spectacular, because they had much lower errors than both Spearman and Pearson. If there was a way to
resolve the coverage issue, Euclidean similarity calculations could be the best option by far. Part of the reason why we had the coverage issue for both Euclidean
and item-based CF was because we only used ùëõ = 100 most similar users while creating the similarity matrices. Therefore, future work could include tuning this
parameter to examine how it influences errors and the number of recommendations generated by Euclidean similarities although it would probably increase the
computation time as well.

During our experimentation, we did not use t-tests to accept/reject our hypotheses. Therefore, there is improvement for further studies to calculate the p-values to
statistically accept/reject our hypotheses. This future work can determine whether or not our results were statsistically significant.

__Last but not least, future work can re-run these tests with larger data-sets provided by MovieLens (e.g. ML20-M) to confirm that our results are still valid on
larger datasets, and look at the effects on accuracy of a larger dataset.__

1. _Jonathan L. Herlocker, Joseph A. Konstan, Al Borchers, and John Riedl. 1999. An Algorithmic Framework for Performing Collaborative Filtering. In
Proceedings of the 1999 Conference on Research and Development in Information Retrieval. 230‚Äì237._
